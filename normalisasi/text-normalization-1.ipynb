{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im feeling rather rotten so im not very ambitious right now;sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im updating my blog because i feel shitty;sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little vain when i did this on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i cant walk into a shop anywhere where i do no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  im feeling rather rotten so im not very ambitious right now;sadness\n",
       "0  im updating my blog because i feel shitty;sadness                 \n",
       "1  i never make her separate from me because i do...                 \n",
       "2  i left with my bouquet of red and yellow tulip...                 \n",
       "3  i was feeling a little vain when i did this on...                 \n",
       "4  i cant walk into a shop anywhere where i do no...                 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_train = pd.read_csv('./test.txt')\n",
    "#data_train.columns = [\"tanggal\", \"tweet\"]\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('spellcheck.txt').read()))\n",
    "# WORDS = Counter(words(open('..\\\\resources\\\\spellcheck.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    # \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    # \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    # \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    # \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    # \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)] # [('', 'kemarin'), ('k', 'emarin'), ('ke', 'marin'), dst]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R] # ['emarin', 'kmarin', 'kearin', dst]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1] # ['ekmarin', 'kmearin', 'keamrin', dst]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters] # ['aemarin', 'bemarin', 'cemarin', dst]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters] # ['akemarin', 'bkemarin', 'ckemarin', dst]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    # \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "  \n",
    "# print('yg = ', end='')\n",
    "# coba = correction(\"yg\")\n",
    "# print(coba)\n",
    "\n",
    "# editsas = len(set(edits2(\"bagamana\")))\n",
    "# print(editsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import modulenorm.modSpellChecker as sc\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "character = ['.',',',';',':','-,','...','?','!','(',')','[',']','{','}','<','>','\"','/','\\'','#','-','@']\n",
    "emoticon = [':)',':]','=)',':-)',':(',':[','=(',':-(',':p',':P','=P',':-p',':-P',':D','=D',':-D',':o',':O',':-o',':-O',';)',';-)','8-)','B-)','^_^','-_-','>:o','>:O',':v',':3','8|','B|','8-|','B-|','>:(',':/',':\\\\',':-/',':-\\\\',':\\'(','O:)',':*',':-*','<3','(y)','(Y)']\n",
    "remove_charac = ['—','…']\n",
    "\n",
    "class normalize():\n",
    "\tdef enterNormalize(self, text):\n",
    "\t\tnorm_enter = text.replace(\"\\n\", \" \")\n",
    "\t\treturn norm_enter\n",
    "\n",
    "\tdef lowerNormalize(self, text):\n",
    "\t\tnorm_lower = text.lower()\n",
    "\t\treturn norm_lower\n",
    "\n",
    "\tdef repeatcharNormalize(self, text):\n",
    "\t\tfor i in range(len(character)):\n",
    "\t\t\tcharac_long = 5\n",
    "\t\t\twhile charac_long>=2:\n",
    "\t\t\t\tchar = character[i]*charac_long \n",
    "\t\t\t\ttext = text.replace(char,character[i])\n",
    "\t\t\t\tcharac_long -= 1\n",
    "\t\treturn text\n",
    "\n",
    "\tdef spacecharNormalize(self, text):\n",
    "\t\ttext = re.sub(r'([' + ''.join(map(re.escape, character)) + r'])(?=\\S)', r'\\1 ', text)\n",
    "\t\ttext = re.sub(r'(\\S)([' + ''.join(map(re.escape, character)) + r'])', r'\\1 \\2', text)\n",
    "\t\treturn text\n",
    "\n",
    "\tdef linkNormalize(self, text):\n",
    "\t\ttext = re.sub(r\"\\s—\\s\", \"\", text)\n",
    "\t\ttext = re.sub(r\"http\\S+\", \"\", text)\n",
    "\t\treturn text\n",
    "\n",
    "\tdef wordcNormalize(self, text, loop=2):\n",
    "\t\tfor a in range(loop):\n",
    "\t\t\tcheckw = False\n",
    "\t\t\tfor i in range(len(text)):\n",
    "\t\t\t\tif text[i] == '-':\n",
    "\t\t\t\t\tif text[i-1] == text[i+1]:\n",
    "\t\t\t\t\t\tkatalengkap = text[i-1]+text[i]+text[i+1]\n",
    "\t\t\t\t\t\tpb = i-1\n",
    "\t\t\t\t\t\tcheckw = True\n",
    "\t\t\tif checkw:\n",
    "\t\t\t\tdel text[pb]\n",
    "\t\t\t\tdel text[pb]\n",
    "\t\t\t\tdel text[pb]\n",
    "\t\t\t\ttext.insert(pb, katalengkap)\n",
    "\t\treturn text\n",
    "\n",
    "\tdef emoticonNormalize(self, text):\n",
    "\t\tdef tighten_emoticon(matchobj):\n",
    "\t\t    return matchobj.group(0).replace(\" \", \"\")\n",
    "\n",
    "\t\tREGEX = '|'.join([re.escape(' '.join(x)) for x in emoticon])\n",
    "\t\ttightened = re.sub(REGEX, tighten_emoticon, text)\n",
    "\t\treturn tightened\n",
    "\n",
    "\tdef ellipsisNormalize(self, text):\n",
    "\t\ttext = text.replace('…',' …')\n",
    "\t\ttext = text.replace(' …','')\n",
    "\t\treturn text\n",
    "\n",
    "\tdef spellNormalize(self, text):\n",
    "\t\tspellCheck = []\n",
    "\t\tfor i in text:\n",
    "\t\t\tif i not in character:\n",
    "\t\t\t\tj = sc.correction(i)\n",
    "\t\t\t\tspellCheck.append(j)\n",
    "\t\t\telse:\n",
    "\t\t\t\tspellCheck.append(i)\n",
    "\t\treturn spellCheck\n",
    "\n",
    "\tdef stemmingNormalize(self, text, datatype='sentence'):\n",
    "\t\tfactory = StemmerFactory()\n",
    "\t\tstemmer = factory.create_stemmer()\n",
    "\n",
    "\t\tif datatype == 'sentence':\n",
    "\t\t\toutput = stemmer.stem(text)\n",
    "\t\t\treturn output\n",
    "\t\telif datatype == 'word':\n",
    "\t\t\toutput = []\n",
    "\t\t\tfor i in text:\n",
    "\t\t\t\tif i in character or i in emoticon:\n",
    "\t\t\t\t\toutput.append(i)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tstemmed = stemmer.stem(i)\n",
    "\t\t\t\t\toutput.append(stemmed)\n",
    "\t\t\treturn output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulenorm.modNormalize import normalize\n",
    "from modulenorm.modTokenizing import tokenize\n",
    "\n",
    "data_train = pd.read_csv('./test.txt')\n",
    "#data_train.columns = [\"tanggal\", \"tweet\"]\n",
    "\n",
    "# menampilkan\n",
    "no = 1\n",
    "for row in data_train:\n",
    "\ttext = row[2].encode(\"utf-8\")\n",
    "\ttext_decode = str(text.decode(\"utf-8\"))\n",
    "\n",
    "\tusenorm = normalize()\n",
    "\ttext_norm = usenorm.enterNormalize(text_decode) # normalisasi enter, 1 revw 1 baris\n",
    "\t# text_norm = usenorm.lowerNormalize(text_norm) # normalisasi huruf besar ke kecil\n",
    "\ttext_norm = usenorm.repeatcharNormalize(text_norm) # normalisasi titik yang berulang\n",
    "\ttext_norm = usenorm.linkNormalize(text_norm) # normalisasi link dalam text\n",
    "\ttext_norm = usenorm.spacecharNormalize(text_norm) # normalisasi spasi karakter\n",
    "\ttext_norm = usenorm.ellipsisNormalize(text_norm) # normalisasi elepsis (…)\n",
    "\n",
    "\ttok = tokenize() # panggil modul tokenisasi\n",
    "\ttext_norm = tok.WordTokenize(text_norm) # pisah tiap kata pada kalimat\n",
    "\n",
    "\ttext_norm = usenorm.spellNormalize(text_norm) # cek spell dari kata perkata\n",
    "\ttext_norm = usenorm.wordcNormalize(text_norm,2) # menyambung kata (malam-malam) (param: textlist, jmlh_loop)\n",
    "\t# text_norm = usenorm.stemmingNormalize(text_norm,'word') # mengubah ke bentuk kata dasar (text, type_data)\n",
    "\n",
    "\ttext_norm = ' '.join(text_norm) # menggabung kalimat tokenize dengan separate spasi\n",
    "\n",
    "\ttext_norm = usenorm.emoticonNormalize(text_norm) # menggabung struktur emoticon yang terpisah ([: - )] = [:-)])\n",
    "\n",
    "\t# walking2\n",
    "\t# konfer @ ke at untuk penunjuk tempat\n",
    "\n",
    "\toutput = open(\"output.txt\",\"a\")\n",
    "\toutput.write(str(text_norm))\n",
    "\toutput.write('\\n')\n",
    "\toutput.close()\n",
    "\t\n",
    "\t# print(no)\n",
    "\tno += 1\n",
    "\n",
    "# tutup koneksi\n",
    "#cur.close()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im feeling rather rotten so im not very ambitious right now;sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im updating my blog because i feel shitty;sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little vain when i did this on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i cant walk into a shop anywhere where i do no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  im feeling rather rotten so im not very ambitious right now;sadness\n",
       "0  im updating my blog because i feel shitty;sadness                 \n",
       "1  i never make her separate from me because i do...                 \n",
       "2  i left with my bouquet of red and yellow tulip...                 \n",
       "3  i was feeling a little vain when i did this on...                 \n",
       "4  i cant walk into a shop anywhere where i do no...                 "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(\"normal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
